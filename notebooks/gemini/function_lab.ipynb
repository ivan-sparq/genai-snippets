{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6197fbca-2729-4a6b-8099-10942a86b786",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip3 install --upgrade --quiet --user google-cloud-aiplatform==1.88.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca25a34-c96a-4418-8935-079b0619e651",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0517865-1d9f-4b9a-926e-a838ee0d3a97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwiklabs-gcp-04-ddc770beb944\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "\n",
    "PROJECT_ID = ! gcloud config get-value project\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "print(PROJECT_ID)\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35cf7f34-6508-49aa-9d05-00bb1a86dfe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from vertexai.generative_models import (\n",
    "    Content,\n",
    "    FunctionDeclaration,\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    "    Tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00bfd431-234b-419b-ae11-ee8af57b65aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Define a function to add two numerical inputs and return the result.\n",
    "# Keep the print statement within the function.\n",
    "def add(a: int |float,b: int |float) -> int |float:\n",
    "    \"\"\" \n",
    "    Adds 2 numbers together \n",
    "    Args:\n",
    "    a: first number\n",
    "    b: second number\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Calling add function\")\n",
    "    return a+b\n",
    "\n",
    "\n",
    "# TODO: Define a function to multiply two numerical inputs and return the result.\n",
    "# Keep the print statement within the function.\n",
    "def multiply(a: int |float,b: int |float) -> int |float:\n",
    "    \"\"\" \n",
    "    Multiplies 2 numbers together \n",
    "    Args:\n",
    "    a: first number\n",
    "    b: second number\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Calling multiply function\")\n",
    "    return a*b\n",
    "\n",
    "# TODO: Create FunctionDeclarations for your functions\n",
    "\n",
    "add_func = FunctionDeclaration.from_func(add)\n",
    "multiply_func = FunctionDeclaration.from_func(multiply)\n",
    "math_tool = Tool(\n",
    "        function_declarations=[add_func,multiply_func ]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc5ff968-d5df-4b25-8697-de29547777a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize Gemini model\n",
    "model = GenerativeModel(\n",
    "    model_name=\"gemini-2.0-flash-001\",\n",
    "    generation_config = GenerationConfig(temperature=0),\n",
    "    tools=[math_tool],\n",
    "    system_instruction = [\n",
    "              Part.from_text(\"\"\"\n",
    "    - Fulfill the user's instructions, including telling jokes.\n",
    "    - If asked to add or multiply numbers, call the provided functions.\n",
    "    - You may call one function after the other if needed.\n",
    "    - Repeat the result to the user.\n",
    "    \"\"\"),\n",
    "    ],\n",
    ")\n",
    "chat = model.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "acd42c8b-1c94-4ca3-8172-a87e09aab929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_response(response):\n",
    "    \"\"\"\n",
    "    Handles the model's response, executing function calls if requested\n",
    "    and recursively calling itself to process the final result.\n",
    "    \"\"\"\n",
    "    # If there are no function calls, print the text response and exit.\n",
    "    if not response.candidates[0].function_calls:\n",
    "        print(f\"{response.text}\\n\")\n",
    "        return\n",
    "\n",
    "    # If there is a function call, process it.\n",
    "    function_calls = response.candidates[0].function_calls\n",
    "    \n",
    "    function_response_parts = []\n",
    "    \n",
    "    for function_call in function_calls:\n",
    "        # Check which function is being called\n",
    "        if function_call.name == \"add\":\n",
    "            args = function_call.args\n",
    "            result = add(a=args['a'], b=args['b'])\n",
    "            api_response = {'result': result}\n",
    "        \n",
    "        elif function_call.name == \"multiply\":\n",
    "            args = function_call.args\n",
    "            result = multiply(a=args['a'], b=args['b'])\n",
    "            api_response = {'result': result}\n",
    "        \n",
    "        else:\n",
    "            # Should not happen with the current setup\n",
    "            print(f\"Unknown function call: {function_call.name}\")\n",
    "            continue\n",
    "\n",
    "        # Create the function response part\n",
    "        function_response_parts.append(\n",
    "            Part.from_function_response(\n",
    "                name=function_call.name,\n",
    "                response=api_response\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # --- This is the key part ---\n",
    "    # 1. Send the function response(s) back to the model.\n",
    "    # print(\"Sending function result back to the model...\")\n",
    "    new_response = chat.send_message(\n",
    "        function_response_parts\n",
    "    )\n",
    "    \n",
    "    # 2. Make the recursive call to handle the model's new response.\n",
    "    # This response will contain the natural language summary.\n",
    "    handle_response(new_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16257e84-a250-4af6-aae4-5170235cbafa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the bicycle fall over? Because it was two tired!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Tell me a joke?\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca3afbed-f331-4364-a87c-0723c947307a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling multiply function\n",
      "112\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"I have 7 pizzas each with 16 slices. How many slices do I have?\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ace5c534-927a-4237-a083-59a8bbb3bbaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add function\n",
      "7\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Doug brought 3 pizzas. Andrew brought 4 pizzas. How many pizzas did they bring together?\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8e7cbc25-9187-498e-91b8-6eb11d16c936",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add function\n",
      "Calling multiply function\n",
      "There are 112 slices.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Doug brought 3 pizzas. Andrew brought 4 pizzas. There are 16 slices per pizza. How many slices are there?\")\n",
    "handle_response(response)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9fb088a1-8468-44f7-9c16-218c2051b775",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling add function\n",
      "There are 2 pizzas left.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Doug brought 4 pizzas, but Andrew dropped 2 on the ground. How many pizzas are left?\")\n",
    "handle_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f88a2-114c-4b85-a6fd-ae2ecb7d2cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1672f2-b67c-4388-885c-ab6bd8fb68fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
