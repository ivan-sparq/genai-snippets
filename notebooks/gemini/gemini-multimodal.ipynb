{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f9a679a",
   "metadata": {},
   "source": [
    "Source: [Multimodality with Gemini](https://partner.cloudskillsboost.google/paths/2294/course_templates/1397/labs/566670)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8dc0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1814ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helper functions\n",
    "\"\"\"\n",
    "\n",
    "import http.client\n",
    "import typing\n",
    "import urllib.request\n",
    "\n",
    "import IPython.display\n",
    "\n",
    "# PIL is imported from the pillow package\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "\n",
    "def display_images(\n",
    "    images: typing.Iterable[Image],\n",
    "    max_width: int = 600,\n",
    "    max_height: int = 350,\n",
    ") -> None:\n",
    "    \"\"\"Display a collection of images in a Jupyter notebook with size constraints.\n",
    "    \n",
    "    This function takes an iterable of Vertex AI Image objects and displays them\n",
    "    in the notebook. Images are automatically resized if they exceed the specified\n",
    "    maximum dimensions while maintaining aspect ratio.\n",
    "    \n",
    "    Args:\n",
    "        images: An iterable of Vertex AI Image objects to display.\n",
    "        max_width: Maximum width in pixels for displayed images. Defaults to 600.\n",
    "        max_height: Maximum height in pixels for displayed images. Defaults to 350.\n",
    "        \n",
    "    Returns:\n",
    "        None. Images are displayed directly in the notebook.\n",
    "        \n",
    "    Note:\n",
    "        Images are converted to RGB mode for compatibility with Jupyter environments.\n",
    "        The function uses PIL's contain method to resize images while preserving\n",
    "        aspect ratio.\n",
    "    \"\"\"\n",
    "    for image in images:\n",
    "        pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
    "        if pil_image.mode != \"RGB\":\n",
    "            # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
    "            pil_image = pil_image.convert(\"RGB\")\n",
    "        image_width, image_height = pil_image.size\n",
    "        if max_width < image_width or max_height < image_height:\n",
    "            # Resize to display a smaller notebook image\n",
    "            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "        IPython.display.display(pil_image)\n",
    "\n",
    "\n",
    "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
    "    \"\"\"Download image data from a URL and return as bytes.\n",
    "    \n",
    "    This function fetches image data from a given URL and returns the raw bytes.\n",
    "    It's a utility function used by load_image_from_url to download images\n",
    "    from web URLs.\n",
    "    \n",
    "    Args:\n",
    "        image_url: The URL of the image to download.\n",
    "        \n",
    "    Returns:\n",
    "        The image data as bytes.\n",
    "        \n",
    "    Raises:\n",
    "        urllib.error.URLError: If the URL cannot be opened or the image cannot be downloaded.\n",
    "        http.client.HTTPException: If there's an HTTP error during the request.\n",
    "    \"\"\"\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "        response = typing.cast(http.client.HTTPResponse, response)\n",
    "        image_bytes = response.read()\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "def load_image_from_url(image_url: str) -> Image:\n",
    "    \"\"\"Load an image from a URL and convert it to a Vertex AI Image object.\n",
    "    \n",
    "    This function downloads an image from a given URL and converts it to a\n",
    "    Vertex AI Image object that can be used with Gemini models for multimodal\n",
    "    processing.\n",
    "    \n",
    "    Args:\n",
    "        image_url: The URL of the image to load.\n",
    "        \n",
    "    Returns:\n",
    "        A Vertex AI Image object containing the downloaded image data.\n",
    "        \n",
    "    Raises:\n",
    "        urllib.error.URLError: If the URL cannot be opened or the image cannot be downloaded.\n",
    "        ValueError: If the downloaded data cannot be converted to a valid image.\n",
    "    \"\"\"\n",
    "    image_bytes = get_image_bytes_from_url(image_url)\n",
    "    return Image.from_bytes(image_bytes)\n",
    "\n",
    "\n",
    "def display_content_as_image(content: str | Image | Part) -> bool:\n",
    "    \"\"\"Display content if it's an image, otherwise return False.\n",
    "    \n",
    "    This function checks if the given content is a Vertex AI Image object and\n",
    "    displays it if so. It's used as part of the multimodal content display\n",
    "    pipeline to handle different content types appropriately.\n",
    "    \n",
    "    Args:\n",
    "        content: The content to check and potentially display. Can be a string,\n",
    "                Vertex AI Image, or Part object.\n",
    "                \n",
    "    Returns:\n",
    "        True if the content was an image and was displayed, False otherwise.\n",
    "    \"\"\"\n",
    "    if not isinstance(content, Image):\n",
    "        return False\n",
    "    display_images([content])\n",
    "    return True\n",
    "\n",
    "\n",
    "def display_content_as_video(content: str | Image | Part) -> bool:\n",
    "    \"\"\"Display content if it's a video Part, otherwise return False.\n",
    "    \n",
    "    This function checks if the given content is a Part object containing video\n",
    "    data and displays it if so. It converts Google Cloud Storage URIs to\n",
    "    publicly accessible URLs for video playback in the notebook.\n",
    "    \n",
    "    Args:\n",
    "        content: The content to check and potentially display. Can be a string,\n",
    "                Vertex AI Image, or Part object.\n",
    "                \n",
    "    Returns:\n",
    "        True if the content was a video and was displayed, False otherwise.\n",
    "        \n",
    "    Note:\n",
    "        This function assumes the Part object contains a file_uri that points to\n",
    "        a Google Cloud Storage location. It converts gs:// URIs to HTTPS URLs\n",
    "        for public access.\n",
    "    \"\"\"\n",
    "    if not isinstance(content, Part):\n",
    "        return False\n",
    "    part = typing.cast(Part, content)\n",
    "    file_path = part.file_data.file_uri.removeprefix(\"gs://\")\n",
    "    video_url = f\"https://storage.googleapis.com/{file_path}\"\n",
    "    IPython.display.display(IPython.display.Video(video_url, width=600))\n",
    "    return True\n",
    "\n",
    "\n",
    "def print_multimodal_prompt(contents: list[str | Image | Part]) -> None:\n",
    "    \"\"\"Print and display multimodal content for readability.\n",
    "    \n",
    "    Given a list of contents that would be sent to Gemini (text, images, videos),\n",
    "    this function displays each content type appropriately. Images and videos\n",
    "    are displayed using their respective display functions, while text content\n",
    "    is printed to the console.\n",
    "    \n",
    "    This function is useful for debugging and understanding what content is\n",
    "    being sent to multimodal AI models like Gemini.\n",
    "    \n",
    "    Args:\n",
    "        contents: A list of content items that can include strings (text),\n",
    "                 Vertex AI Image objects, or Part objects (videos).\n",
    "                 \n",
    "    Returns:\n",
    "        None. Content is displayed directly in the notebook or printed to console.\n",
    "        \n",
    "    Example:\n",
    "        >>> contents = [\"Describe this image:\", image_obj, \"What do you see?\"]\n",
    "        >>> print_multimodal_prompt(contents)\n",
    "        # This will display the image and print the text prompts\n",
    "    \"\"\"\n",
    "    for content in contents:\n",
    "        if display_content_as_image(content):\n",
    "            continue\n",
    "        if display_content_as_video(content):\n",
    "            continue\n",
    "        print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a1917b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}